{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":8700156,"sourceType":"datasetVersion","datasetId":5218014}],"dockerImageVersionId":30746,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-07-27T05:08:10.049298Z"}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Installing and importing dependencies","metadata":{}},{"cell_type":"code","source":"!pip install chardet\n!pip install dash\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.express as px\nimport chardet\nimport plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\nimport dash\nfrom dash import dcc\nfrom dash import html \nfrom dash.dependencies import Input, Output","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import warnings\nwarnings.filterwarnings('ignore')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with open('/kaggle/input/most-streamed-spotify-songs-2024/Most Streamed Spotify Songs 2024.csv', 'rb') as file:\n    data = file.read(200000)\n    result = chardet.detect(data)\n    encoding = result['encoding']\n    print(f\"Detected encoding: {encoding}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Importing the dataset","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/most-streamed-spotify-songs-2024/Most Streamed Spotify Songs 2024.csv',encoding=\"ISO-8859-1\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Shape of the data\ndf.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Understanding the datatypes","metadata":{}},{"cell_type":"code","source":"df.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* here datatypes are need to be changed","metadata":{}},{"cell_type":"code","source":"df.isnull().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.drop(columns=['Soundcloud Streams','TIDAL Popularity'], axis=1,inplace=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def remove(x):\n    return x.replace(\",\",\"\")\n\ndf[\"All Time Rank\"]=df[\"All Time Rank\"].apply(remove)\ndf[\"All Time Rank\"]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.to_numeric(df[\"All Time Rank\"])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def remove(x):\n    return x.replace(\",\",\"\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df[\"Release Date\"]=pd.to_datetime(df[\"Release Date\"])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = df.map(lambda x: x.replace(',','') if isinstance(x,str) else x)\ndf","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for x in df.columns[6:]:\n    df[x] = pd.to_numeric(df[x],downcast=\"integer\")\n    print(df[x].dtype)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.info()\n# Data types has been correctly assigned based on the columns data","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Treating Missing Values","metadata":{}},{"cell_type":"code","source":"df.isnull().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.dropna(subset=\"Artist\",inplace=True)\n# since 5 values are missing in artist column its better to drop these rows","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df[\"Artist\"].isnull().sum()\n# Null values are removed in artist column","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# In Spotify Streams there are 113 null values\ndf[\"Spotify Streams\"].plot(kind=\"kde\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Since the data is right skewed we impute null values with median\ndf[\"Spotify Streams\"].fillna(df[\"Spotify Streams\"].median(),inplace=True)\ndf[\"Spotify Streams\"].isnull().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Null values are removed in Spotify Streams column","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df[\"Spotify Playlist Count\"].plot(kind=\"kde\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in df.select_dtypes(np.number):\n    print(i,round(df[i].skew(),2))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in df.columns[7:27]:\n    df[i].fillna(df[i].median(),inplace=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.drop_duplicates()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"df.isnull().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.svm import SVR\nfrom sklearn.metrics import mean_squared_error","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.columns\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Linear Regression Model: Training and Evaluation","metadata":{}},{"cell_type":"code","source":"features = ['Spotify Streams', 'All Time Rank','YouTube Views','Pandora Streams', 'TikTok Likes', 'TikTok Posts','Apple Music Playlist Count', 'Spotify Playlist Count', 'Spotify Playlist Reach','Amazon Playlist Count']\ntarget = 'Spotify Popularity'\n\nX = df[features]\ny = df[target]\n\n# Split data\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n\n# Train model\nmodel = LinearRegression()\nmodel.fit(X_train, y_train)\n\n# Predict and evaluate\ny_pred = model.predict(X_test)\nmse = mean_squared_error(y_test, y_pred)\nprint(f'Linear Regression Mean Squared Error: {mse}')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\n\n# **Random Forest Regressor: Training and Evaluation**","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_squared_error\n\n# Define and train the Random Forest model\nrf_model = RandomForestRegressor(n_estimators=100, random_state=42)\nrf_model.fit(X_train, y_train)\n\n# Predict and evaluate\ny_pred_rf = rf_model.predict(X_test)\nmse_rf = mean_squared_error(y_test, y_pred_rf)\nprint(f'Random Forest Regressor Mean Squared Error: {mse_rf}')\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Feature Importance Analysis","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Get feature importances\nimportances = rf_model.feature_importances_\nfeature_names = X.columns\n\n# Create a DataFrame for visualization\nimportance_df = pd.DataFrame({'Feature': feature_names, 'Importance': importances})\nimportance_df = importance_df.sort_values(by='Importance', ascending=False)\n\n# Plot feature importances\nplt.figure(figsize=(12, 8))\nsns.barplot(x='Importance', y='Feature', data=importance_df)\nplt.title('Feature Importance Analysis')\nplt.show()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Gradient Boosting Regressor: Training and Evaluation","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import GradientBoostingRegressor\n\ngbm = GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=10)\ngbm.fit(X_train, y_train)\ny_pred_gbm = gbm.predict(X_test)\n\nmse_gbm = mean_squared_error(y_test, y_pred_gbm)\nprint(f'Gradient Boosting Regressor Mean Squared Error: {mse_gbm}')\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Gradient Boosting Feature Importance Analysis","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Get feature importances\nimportances = gbm.feature_importances_\nfeature_names = X.columns\n\n# Create a DataFrame for visualization\nimportance_df = pd.DataFrame({'Feature': feature_names, 'Importance': importances})\nimportance_df = importance_df.sort_values(by='Importance', ascending=False)\n\n# Plot feature importances\nplt.figure(figsize=(12, 8))\nsns.barplot(x='Importance', y='Feature', data=importance_df)\nplt.title('Feature Importance Analysis')\nplt.show()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# CatBoost Regressor: Training and Evaluation","metadata":{}},{"cell_type":"code","source":"from catboost import CatBoostRegressor\n\ncatboost = CatBoostRegressor(iterations=100, learning_rate=0.1, depth=6, verbose=0)\ncatboost.fit(X_train, y_train)\ny_pred_catboost = catboost.predict(X_test)\n\nmse_catboost = mean_squared_error(y_test, y_pred_catboost)\nprint(f'CatBoost Regressor Mean Squared Error: {mse_catboost}')\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# CatBoost Regressor: Hyperparameter Tuning with GridSearchCV","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV\n\nparam_grid = {\n    'iterations': [100, 200, 300],\n    'learning_rate': [0.01, 0.05, 0.1],\n    'depth': [4, 6, 8],\n}\n\ncatboost = CatBoostRegressor(verbose=0)\ngrid_search = GridSearchCV(estimator=catboost, param_grid=param_grid, cv=3, scoring='neg_mean_squared_error', n_jobs=-1)\ngrid_search.fit(X_train, y_train)\n\nbest_catboost = grid_search.best_estimator_\ny_pred_best_catboost = best_catboost.predict(X_test)\nmse_best_catboost = mean_squared_error(y_test, y_pred_best_catboost)\nprint(f'Best CatBoost Regressor Mean Squared Error: {mse_best_catboost}')\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Stacking Regressor: Model Training and Evaluation","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import StackingRegressor\nfrom sklearn.linear_model import RidgeCV\n\nestimators = [\n    ('rf', RandomForestRegressor(n_estimators=100, random_state=10)),\n    ('catboost', CatBoostRegressor(iterations=100, learning_rate=0.1, depth=6, verbose=0))\n]\n\nstack = StackingRegressor(estimators=estimators, final_estimator=RidgeCV())\nstack.fit(X_train, y_train)\ny_pred_stack = stack.predict(X_test)\n\nmse_stack = mean_squared_error(y_test, y_pred_stack)\nprint(f'Stacking Regressor Mean Squared Error: {mse_stack}')\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}